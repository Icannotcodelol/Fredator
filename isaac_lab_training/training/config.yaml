algorithm: PPO
learning_rate: 0.0003
n_steps: 2048
batch_size: 2048
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
total_timesteps: 10000000
num_envs: 4096
clip_obs: 10.0
clip_reward: 10.0
hidden_layers: [256, 256, 128]
activation: relu
